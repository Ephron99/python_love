{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f012b49-b38e-4b5f-a0a2-797ec324d9ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "\n",
    "# Suppress TensorFlow informational messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "# --- 2. Load and Prepare the MNIST Dataset ---\n",
    "print(\"\\n--- Loading and Preparing MNIST Data ---\")\n",
    "# We only need the images (X) for this unsupervised task.\n",
    "(x_train, _), (_, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data for a GAN\n",
    "# 1. Add a channel dimension (for Conv2D layers).\n",
    "# 2. Normalize pixel values to the [-1, 1] range, which is standard for GANs with a tanh activation.\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "x_train = (x_train - 127.5) / 127.5\n",
    "\n",
    "# Create a TensorFlow Dataset for efficient batching\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "print(f\"Data loaded. Shape of training data: {x_train.shape}\")\n",
    "\n",
    "\n",
    "# --- 3. Define the GAN Components (Generator and Discriminator) ---\n",
    "\n",
    "LATENT_DIM = 128\n",
    "\n",
    "# The Generator model (The Art Forger)\n",
    "def make_generator_model():\n",
    "    model = keras.Sequential(name=\"generator\")\n",
    "    model.add(layers.Input(shape=(LATENT_DIM,)))\n",
    "    model.add(layers.Dense(7 * 7 * 256, use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    return model\n",
    "\n",
    "# The Discriminator model (The Art Critic)\n",
    "def make_discriminator_model():\n",
    "    model = keras.Sequential(name=\"discriminator\")\n",
    "    model.add(layers.Input(shape=(28, 28, 1)))\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1)) # No activation, outputs a raw score (logit)\n",
    "    return model\n",
    "\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "print(\"\\nGenerator and Discriminator models built.\")\n",
    "\n",
    "\n",
    "# --- 4. Define the WGAN-GP Model with Custom Training Logic ---\n",
    "\n",
    "class WGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim, discriminator_extra_steps=5, gp_weight=10.0):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = discriminator_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "        \n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        \n",
    "        for i in range(self.d_steps):\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_images = self.generator(random_latent_vectors, training=True)\n",
    "                fake_logits = self.discriminator(fake_images, training=True)\n",
    "                real_logits = self.discriminator(real_images, training=True)\n",
    "                \n",
    "                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
    "                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "            \n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            self.d_optimizer.apply_gradients(zip(d_gradient, self.discriminator.trainable_variables))\n",
    "            \n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_images = self.generator(random_latent_vectors, training=True)\n",
    "            gen_img_logits = self.discriminator(generated_images, training=True)\n",
    "            g_loss = self.g_loss_fn(gen_img_logits)\n",
    "            \n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_variables))\n",
    "        \n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n",
    "\n",
    "# Create a callback to save generated images during training\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=16, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seed = tf.random.normal([num_img, latent_dim])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % 5 == 0 or (epoch + 1) == EPOCHS:\n",
    "            predictions = self.model.generator(self.seed, training=False)\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "            \n",
    "            for i in range(self.num_img):\n",
    "                plt.subplot(4, 4, i + 1)\n",
    "                plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.savefig(f'generated_image_epoch_{epoch+1:03d}.png')\n",
    "            print(f'\\nSaved sample images for epoch {epoch+1}.')\n",
    "            plt.close(fig)\n",
    "\n",
    "# --- 5. Compile and Train the WGAN-GP ---\n",
    "print(\"\\n--- Training the WGAN-GP (this will take a long time)... ---\")\n",
    "EPOCHS = 50\n",
    "\n",
    "# Instantiate optimizers for the two models\n",
    "generator_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n",
    "discriminator_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "# Define the loss functions\n",
    "def discriminator_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)\n",
    "\n",
    "# Instantiate and compile the GAN model\n",
    "wgan = WGAN(\n",
    "    discriminator=discriminator,\n",
    "    generator=generator,\n",
    "    latent_dim=LATENT_DIM\n",
    ")\n",
    "wgan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    "    g_loss_fn=generator_loss,\n",
    "    d_loss_fn=discriminator_loss,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "wgan.fit(\n",
    "    train_dataset, \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=[GANMonitor(num_img=16, latent_dim=LATENT_DIM)]\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete.\")\n",
    "\n",
    "# --- 6. Generate and Visualize Final Results ---\n",
    "print(\"\\n--- Generating Final Grid of Digits ---\")\n",
    "final_seed = tf.random.normal([100, LATENT_DIM])\n",
    "final_predictions = wgan.generator.predict(final_seed)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i in range(100):\n",
    "    plt.subplot(10, 10, i + 1)\n",
    "    plt.imshow(final_predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle(\"Final AI-Generated Digits from WGAN-GP\", fontsize=16)\n",
    "plt.savefig('final_generated_digits_grid.png')\n",
    "print(\"\\nFinal grid of generated images saved as 'final_generated_digits_grid.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c3c7e-5389-4a8b-a5c4-d5794e2c9ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
